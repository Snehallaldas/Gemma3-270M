{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"bec3ce9a79144d148801a9336222be3c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c7ef6dca8f6e480691a5578341b3275b","IPY_MODEL_732c6df37d4f46279d2d61fc783ef3ce","IPY_MODEL_413a55220c6144a58d200c0e402dcc34"],"layout":"IPY_MODEL_ec1cde1111b94e6c9b9d3575ab5c0ea1"}},"c7ef6dca8f6e480691a5578341b3275b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f77a6ab50b54591a485e2e1438f2786","placeholder":"​","style":"IPY_MODEL_9bd1814164c84f368fdc3a8947e7c6fe","value":"  1%"}},"732c6df37d4f46279d2d61fc783ef3ce":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d1197eb129c4541a2de14fe9e258f37","max":150000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fb98831d3fee41ccbac3db0ffa3e0ac4","value":1660}},"413a55220c6144a58d200c0e402dcc34":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de476eb1086943e0a3f31882a039d4f6","placeholder":"​","style":"IPY_MODEL_1e4a14a5ee0e495aa9c91e91f9081510","value":" 1660/150000 [1:09:26&lt;64:05:36,  1.56s/it]"}},"ec1cde1111b94e6c9b9d3575ab5c0ea1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f77a6ab50b54591a485e2e1438f2786":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9bd1814164c84f368fdc3a8947e7c6fe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d1197eb129c4541a2de14fe9e258f37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb98831d3fee41ccbac3db0ffa3e0ac4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"de476eb1086943e0a3f31882a039d4f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e4a14a5ee0e495aa9c91e91f9081510":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/snehallaldas/gemma-3-270m?scriptVersionId=298469932\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"## Import the Dataset","metadata":{"id":"XRJwTtbPOVSe"}},{"cell_type":"code","source":"!pip install datasets","metadata":{"id":"zCB3dCR8MRNb","trusted":true,"execution":{"iopub.status.busy":"2026-02-18T16:33:24.595628Z","iopub.execute_input":"2026-02-18T16:33:24.595962Z","iopub.status.idle":"2026-02-18T16:33:30.157557Z","shell.execute_reply.started":"2026-02-18T16:33:24.595934Z","shell.execute_reply":"2026-02-18T16:33:30.156847Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.4.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.3)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.5)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\nRequirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.18)\nRequirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\nRequirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (26.0rc2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.3)\nRequirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.12.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2026.1.4)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.1rc0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.6.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from datasets import load_dataset\n\nds = load_dataset(\"roneneldan/TinyStories\")","metadata":{"id":"yEfCP8xaOipu","trusted":true,"execution":{"iopub.status.busy":"2026-02-18T16:33:30.159405Z","iopub.execute_input":"2026-02-18T16:33:30.159749Z","iopub.status.idle":"2026-02-18T16:33:53.452039Z","shell.execute_reply.started":"2026-02-18T16:33:30.159718Z","shell.execute_reply":"2026-02-18T16:33:53.451141Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f43a69bacaa400eb104fed8960704b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00000-of-00004-2d5a1467fff108(…):   0%|          | 0.00/249M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35d9d21947734d8b8de1e6be1c97a9ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00001-of-00004-5852b56a2bd28f(…):   0%|          | 0.00/248M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa8437aee698449ead64ae836b9adcc7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00002-of-00004-a26307300439e9(…):   0%|          | 0.00/246M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f93b39c5786045f996945624a2ada2e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00003-of-00004-d243063613e5a0(…):   0%|          | 0.00/248M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b74e53ea034f4042925dead1a41abe00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/validation-00000-of-00001-869c898b5(…):   0%|          | 0.00/9.99M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e93a50ea56fa4e1b998271bb24e7d77b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/2119719 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93238b99727f4480afe7004d2ca0e1ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/21990 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fd3ab30a42749278d453b9c30ec6af3"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"!pip install tiktoken\nimport tiktoken\nimport os\nimport numpy as np\nfrom tqdm.auto import tqdm\n\nenc = tiktoken.get_encoding(\"gpt2\")\n\ndef process(example):\n  ids = enc.encode_ordinary(example['text'])  # encode_ordinary ignores the special tokens\n  out = {'ids': ids, 'len': len(ids)}\n  return out\n\nif not os.path.exists(\"train.bin\"):\n  tokenized = ds.map(\n      process,\n      remove_columns=['text'],\n      desc=\"tokenizing the splits\",\n      num_proc=8,\n      )\n  # concatinate all the ids in each dataset into one large file we can use for training\n  for split,dset in tokenized.items():\n    arr_len = np.sum(dset['len'], dtype=np.uint64)\n    filename = f'{split}.bin'\n    dtype = np.uint16\n    arr = np.memmap(filename, dtype=dtype, mode='w+', shape=(arr_len,))\n    total_batches = 1024\n\n    idx = 0\n    for batch_idx in tqdm(range(total_batches), desc=f'writing {filename}'):\n      batch = dset.shard(num_shards=total_batches, index=batch_idx, contiguous=True).with_format('numpy')\n      arr_batch = np.concatenate(batch['ids'])\n      arr[idx : idx + len(arr_batch)] = arr_batch\n      idx += len(arr_batch)\n    arr.flush()","metadata":{"id":"gIK68MuEOzid","trusted":true,"execution":{"iopub.status.busy":"2026-02-18T16:33:53.453377Z","iopub.execute_input":"2026-02-18T16:33:53.454041Z","iopub.status.idle":"2026-02-18T16:51:47.648453Z","shell.execute_reply.started":"2026-02-18T16:33:53.454002Z","shell.execute_reply":"2026-02-18T16:51:47.647573Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.12.0)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2025.11.3)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2.32.5)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2.6.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2026.1.4)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizing the splits (num_proc=8):   0%|          | 0/2119719 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5725c5912524c5a8999d6cce5c307ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizing the splits (num_proc=8):   0%|          | 0/21990 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4299674b1cf44ceab0182a0f6d46f16"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"writing train.bin:   0%|          | 0/1024 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d40cef0fb85f4ffa9df933f6cb3e9493"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"writing validation.bin:   0%|          | 0/1024 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79734e7f2f6b430f9949b536e0dcd723"}},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"## Create Input and output Batches","metadata":{"id":"--fh2owyS5Mu"}},{"cell_type":"code","source":"def get_batch(split):\n\n    if split == 'train':\n        data = np.memmap('train.bin', dtype=np.uint16, mode='r')\n    else:\n        data = np.memmap('validation.bin', dtype=np.uint16, mode='r')\n    ix = torch.randint(len(data) - block_size, (batch_size,))\n    x = torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in ix])\n    y = torch.stack([torch.from_numpy((data[i+1:i+1+block_size]).astype(np.int64)) for i in ix])\n    if device_type == 'cuda':\n        # pin arrays x,y, which allows us to move them to GPU asynchronously (non_blocking=True)\n        x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)\n    else:\n        x, y = x.to(device), y.to(device)\n    return x, y\n","metadata":{"id":"ClOP-zyHw0_l","trusted":true,"execution":{"iopub.status.busy":"2026-02-18T16:51:47.650416Z","iopub.execute_input":"2026-02-18T16:51:47.650743Z","iopub.status.idle":"2026-02-18T16:51:47.657794Z","shell.execute_reply.started":"2026-02-18T16:51:47.650715Z","shell.execute_reply":"2026-02-18T16:51:47.657293Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Define the SLM Model Architecture","metadata":{"id":"ckHtCt_JVEhF"}},{"cell_type":"code","source":"import torch\ndef compute_rope_params(head_dim, theta_base=10_000, context_length=4096, dtype=torch.float32):\n  assert head_dim % 2 == 0, \"Embedding dimension must be even\"\n\n  # Compute the inverse frequency\n  inv_freq = 1.0 / (theta_base ** (torch.arange(0, head_dim, 2, dtype=dtype)[: (head_dim // 2)].float() / head_dim))\n\n  positions = torch.arange(context_length, dtype=dtype)\n\n  angles = positions[:, None] * inv_freq[None, :]  # Shape: (context_lenght, head_dim // 2)\n\n  angles = torch.cat([angles, angles], dim=1) # Shape: (context_lenght, head_dim)\n\n  cos = torch.cos(angles)\n  sin = torch.sin(angles)\n\n  return cos, sin\n\ndef apply_rope(x, cos, sin):\n  # x: (batch_size, num_heads, seq_len, head_dim)\n  batch_size, num_heads, seq_len, head_dim = x.shape\n  assert head_dim % 2 == 0, \"HEad dimension must be even\"\n\n  # Spliting x into first half and the second half\n  x1 = x[..., : head_dim // 2]\n  x2 = x[..., head_dim // 2 :]\n\n  cos = cos[:seq_len, :].unsqueeze(0).unsqueeze(0)  # Shape (1, 1, seq_len, head_dim)\n  sin = sin[:seq_len, :].unsqueeze(0).unsqueeze(0)\n\n  # Apply the rotary transformation\n  rotated = torch.cat((-x2, x1), dim=-1)\n  x_rotated = (x * cos) + (rotated * sin)\n\n  return x_rotated.to(dtype=x.dtype)","metadata":{"id":"WJJs1tshUyNL","trusted":true,"execution":{"iopub.status.busy":"2026-02-18T16:51:47.658515Z","iopub.execute_input":"2026-02-18T16:51:47.658737Z","iopub.status.idle":"2026-02-18T16:51:47.672934Z","shell.execute_reply.started":"2026-02-18T16:51:47.658706Z","shell.execute_reply":"2026-02-18T16:51:47.672138Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\nfrom dataclasses import dataclass\nimport numpy as np\nfrom tqdm.auto import tqdm\nfrom contextlib import nullcontext\nimport os\n\nclass RMSNorm(nn.Module):\n    def __init__(self, emb_dim, eps=1e-6, bias=False):\n        super().__init__()\n        self.eps = eps\n        # Gemma3 stores zero-centered weights and uses (1 + weight) during forward\n        self.scale = nn.Parameter(torch.zeros(emb_dim))\n        self.shift = nn.Parameter(torch.zeros(emb_dim)) if bias else None\n\n    def forward(self, x):\n        # Match HF Gemma3: compute norm in float32, then scale by (1 + w)\n        input_dtype = x.dtype\n        x_f = x.float()\n        var = x_f.pow(2).mean(dim=-1, keepdim=True)\n        x_norm = x_f * torch.rsqrt(var + self.eps)\n        out = x_norm * (1.0 + self.scale.float())\n\n        if self.shift is not None:\n            out = out + self.shift.float()\n\n        return out.to(input_dtype)\n\n\n\nclass GroupedQueryAttention(nn.Module):\n    def __init__(\n        self, d_in, num_heads, num_kv_groups, head_dim=None, qk_norm=False,\n        query_pre_attn_scalar=None, dtype=None,\n    ):\n        super().__init__()\n        assert num_heads % num_kv_groups == 0, \"num_heads must be divisible by num_kv_groups\"\n\n        self.num_heads = num_heads\n        self.num_kv_groups = num_kv_groups\n        self.group_size = num_heads // num_kv_groups\n\n        if head_dim is None:\n            assert d_in % num_heads == 0, \"`d_in` must be divisible by `num_heads` if `head_dim` is not set\"\n            head_dim = d_in // num_heads\n\n        self.head_dim = head_dim\n        self.d_out = num_heads * head_dim\n\n        self.W_query = nn.Linear(d_in, self.d_out, bias=False, dtype=dtype)\n        self.W_key = nn.Linear(d_in, num_kv_groups * head_dim, bias=False, dtype=dtype)\n        self.W_value = nn.Linear(d_in, num_kv_groups * head_dim, bias=False, dtype=dtype)\n\n        self.out_proj = nn.Linear(self.d_out, d_in, bias=False, dtype=dtype)\n\n        if qk_norm:\n            self.q_norm = RMSNorm(head_dim, eps=1e-6)\n            self.k_norm = RMSNorm(head_dim, eps=1e-6)\n        else:\n            self.q_norm = self.k_norm = None\n\n        if query_pre_attn_scalar is not None:\n            self.scaling = (query_pre_attn_scalar) ** -0.5\n        else:\n            self.scaling = (head_dim) ** -0.5\n\n\n    def forward(self, x, mask, cos, sin):\n        b, num_tokens, _ = x.shape\n\n        # Apply projections\n        queries = self.W_query(x)  # (b, num_tokens, num_heads * head_dim)\n        keys = self.W_key(x)       # (b, num_tokens, num_kv_groups * head_dim)\n        values = self.W_value(x)   # (b, num_tokens, num_kv_groups * head_dim)\n\n        # Reshape\n        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim).transpose(1, 2)\n        keys = keys.view(b, num_tokens, self.num_kv_groups, self.head_dim).transpose(1, 2)\n        values = values.view(b, num_tokens, self.num_kv_groups, self.head_dim).transpose(1, 2)\n\n        # Optional normalization\n        if self.q_norm:\n            queries = self.q_norm(queries)\n        if self.k_norm:\n            keys = self.k_norm(keys)\n\n        # Apply RoPE\n        queries = apply_rope(queries, cos, sin)\n        keys = apply_rope(keys, cos, sin)\n\n        # Expand K and V to match number of heads\n        keys = keys.repeat_interleave(self.group_size, dim=1)\n        values = values.repeat_interleave(self.group_size, dim=1)\n\n        # Scale queries\n        queries = queries * self.scaling\n\n        # Attention\n        attn_scores = queries @ keys.transpose(2, 3)\n        attn_scores = attn_scores.masked_fill(mask, -torch.inf)\n        attn_weights = torch.softmax(attn_scores, dim=-1)\n\n        context = (attn_weights @ values).transpose(1, 2).reshape(b, num_tokens, self.d_out)\n        return self.out_proj(context)\n\nclass FeedForward(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.fc1 = nn.Linear(cfg[\"emb_dim\"], cfg[\"hidden_dim\"], dtype=cfg[\"dtype\"], bias=False)\n        self.fc2 = nn.Linear(cfg[\"emb_dim\"], cfg[\"hidden_dim\"], dtype=cfg[\"dtype\"], bias=False)\n        self.fc3 = nn.Linear(cfg[\"hidden_dim\"], cfg[\"emb_dim\"], dtype=cfg[\"dtype\"], bias=False)\n\n    def forward(self, x):\n        x_fc1 = self.fc1(x)\n        x_fc2 = self.fc2(x)\n        x = nn.functional.gelu(x_fc1, approximate=\"tanh\") * x_fc2\n        return self.fc3(x)\n\n\nclass TransformerBlock(nn.Module):\n\n    def __init__(self, cfg: dict, attn_type: str):\n        super().__init__()\n        self.attn_type = attn_type\n\n        self.att = GroupedQueryAttention(\n            d_in=cfg[\"emb_dim\"],\n            num_heads=cfg[\"n_heads\"],\n            num_kv_groups=cfg[\"n_kv_groups\"],\n            head_dim=cfg[\"head_dim\"],\n            qk_norm=cfg[\"qk_norm\"],\n            query_pre_attn_scalar=cfg[\"query_pre_attn_scalar\"],\n            dtype=cfg[\"dtype\"],\n        )\n        self.ff = FeedForward(cfg)\n        self.input_layernorm = RMSNorm(cfg[\"emb_dim\"], eps=1e-6)\n        self.post_attention_layernorm = RMSNorm(cfg[\"emb_dim\"], eps=1e-6)\n        self.pre_feedforward_layernorm = RMSNorm(cfg[\"emb_dim\"], eps=1e-6)\n        self.post_feedforward_layernorm = RMSNorm(cfg[\"emb_dim\"], eps=1e-6)\n\n    def forward(\n        self,\n        x,\n        mask_global,\n        mask_local,\n        cos_global,\n        sin_global,\n        cos_local,\n        sin_local,\n    ):\n        # Shortcut connection for attention block\n        shortcut = x\n        x = self.input_layernorm(x)\n\n        if self.attn_type == \"sliding_attention\":\n            attn_mask = mask_local\n            cos = cos_local\n            sin = sin_local\n        else:\n            attn_mask = mask_global\n            cos = cos_global\n            sin = sin_global\n\n        x_attn = self.att(x, attn_mask, cos, sin)\n        x_attn = self.post_attention_layernorm(x_attn)\n        x = shortcut + x_attn\n\n        # Shortcut connection for feed forward block\n        shortcut = x\n        x_ffn = self.pre_feedforward_layernorm(x)\n        x_ffn = self.ff(x_ffn)\n        x_ffn = self.post_feedforward_layernorm(x_ffn)\n        x = shortcut + x_ffn\n        return x\n\nclass Gemma3Model(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        assert cfg[\"layer_types\"] is not None and len(cfg[\"layer_types\"]) == cfg[\"n_layers\"]\n\n        # Main model parameters\n        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"], dtype=cfg[\"dtype\"])\n\n        self.blocks = nn.ModuleList([\n            TransformerBlock(cfg, attn_type)for attn_type in cfg[\"layer_types\"]\n        ])\n\n        self.final_norm = RMSNorm(cfg[\"emb_dim\"], eps=1e-6)\n        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False, dtype=cfg[\"dtype\"])\n        self.cfg = cfg\n\n        # Reusuable utilities\n        cos_local, sin_local = compute_rope_params(\n            head_dim=cfg[\"head_dim\"],\n            theta_base=cfg[\"rope_local_base\"],\n            context_length=cfg[\"context_length\"],\n            dtype=torch.float32,\n        )\n        cos_global, sin_global = compute_rope_params(\n            head_dim=cfg[\"head_dim\"],\n            theta_base=cfg[\"rope_base\"],\n            context_length=cfg[\"context_length\"],\n            dtype=torch.float32,\n        )\n        self.register_buffer(\"cos_local\", cos_local, persistent=False)\n        self.register_buffer(\"sin_local\", sin_local, persistent=False)\n        self.register_buffer(\"cos_global\", cos_global, persistent=False)\n        self.register_buffer(\"sin_global\", sin_global, persistent=False)\n\n    def _create_masks(self, seq_len, device):\n        ones = torch.ones((seq_len, seq_len), dtype=torch.bool, device=device)\n\n        mask_global = torch.triu(ones, diagonal=1)\n\n\n        far_past = torch.triu(ones, diagonal=self.cfg[\"sliding_window\"]).T\n\n        mask_local = mask_global | far_past\n        return mask_global, mask_local\n\n    def forward(self, input_ids, targets=None):\n        b, seq_len = input_ids.shape\n        x = self.tok_emb(input_ids) * (self.cfg[\"emb_dim\"] ** 0.5)\n        mask_global, mask_local = self._create_masks(seq_len, x.device)\n\n        for block in self.blocks:\n            x = block(\n                x,\n                mask_global=mask_global,\n                mask_local=mask_local,\n                cos_global=self.cos_global,\n                sin_global=self.sin_global,\n                cos_local=self.cos_local,\n                sin_local=self.sin_local,\n            )\n\n        x = self.final_norm(x)\n        logits = self.out_head(x.to(self.cfg[\"dtype\"]))\n        loss = None\n        if targets is not None:\n            loss = F.cross_entropy(logits.reshape(-1, logits.size(-1)), targets.reshape(-1))\n        return logits, loss\n\n    @torch.no_grad()\n    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n      for _ in range(max_new_tokens):\n        ctx_len = self.cfg[\"context_length\"]\n        idx_cond = idx if idx.size(1) <= ctx_len else idx[:, -ctx_len:]\n        logits, _ = self(idx_cond)  # targets=None by default\n        logits = logits[:, -1, :] / temperature\n        if top_k is not None:\n            v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n            logits[logits < v[:, [-1]]] = float(\"-inf\")\n        probs = F.softmax(logits, dim=-1)\n        idx_next = torch.multinomial(probs, num_samples=1)\n        idx = torch.cat((idx, idx_next), dim=1)\n      return idx\n\n","metadata":{"id":"Gqmrw3BGuOqb","trusted":true,"execution":{"iopub.status.busy":"2026-02-18T16:51:47.674004Z","iopub.execute_input":"2026-02-18T16:51:47.674332Z","iopub.status.idle":"2026-02-18T16:51:47.703614Z","shell.execute_reply.started":"2026-02-18T16:51:47.674302Z","shell.execute_reply":"2026-02-18T16:51:47.703026Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"GEMMA3_CONFIG_270M = {\n    \"vocab_size\": 50257,\n    \"context_length\": 1024,\n    \"emb_dim\": 640,\n    \"n_heads\": 4,\n    \"n_layers\": 18,\n    \"hidden_dim\": 2048,\n    \"head_dim\": 256,\n    \"qk_norm\": True,\n    \"n_kv_groups\": 1,\n    \"rope_local_base\": 10_000.0,\n    \"rope_base\": 1_000_000.0,\n    \"sliding_window\": 512,\n      \"layer_types\": [\n        \"sliding_attention\",\n        \"sliding_attention\",\n        \"sliding_attention\",\n        \"sliding_attention\",\n        \"sliding_attention\",\n        \"full_attention\",\n        \"sliding_attention\",\n        \"sliding_attention\",\n        \"sliding_attention\",\n        \"sliding_attention\",\n        \"sliding_attention\",\n        \"full_attention\",\n        \"sliding_attention\",\n        \"sliding_attention\",\n        \"sliding_attention\",\n        \"sliding_attention\",\n        \"sliding_attention\",\n        \"full_attention\"\n    ],\n    \"dtype\": torch.bfloat16,\n    \"query_pre_attn_scalar\": 256,\n}\n\ntorch.manual_seed(123)\nmodel = Gemma3Model(GEMMA3_CONFIG_270M)","metadata":{"id":"9bQw7bBJ2hiJ","trusted":true,"execution":{"iopub.status.busy":"2026-02-18T16:51:47.70466Z","iopub.execute_input":"2026-02-18T16:51:47.704941Z","iopub.status.idle":"2026-02-18T16:51:50.209781Z","shell.execute_reply.started":"2026-02-18T16:51:47.704919Z","shell.execute_reply":"2026-02-18T16:51:50.208944Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Define the loss function","metadata":{"id":"b5yQjRjK32Sv"}},{"cell_type":"code","source":"# Training Config\nimport torch\nfrom contextlib import nullcontext\n\nlearning_rate = 3e-4 \nmax_iters = 30000 \nwarmup_steps = 1000\nmin_lr = 3e-5\neval_iters = 50 \nbatch_size = 32\nblock_size = 128 \n\ngradient_accumulation_steps = 2\n\ndevice =  \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice_type = 'cuda' if 'cuda' in device else 'cpu' # for later use in torch.autocast\n# note: float16 data type will automatically use a GradScaler\n\ndtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16' # 'float32', 'bfloat16', or 'float16', the latter will auto implement a GradScaler\nptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n\nctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n\ntorch.set_default_device(device)\ntorch.manual_seed(42)","metadata":{"id":"AYjMllsW4EGU","trusted":true,"execution":{"iopub.status.busy":"2026-02-18T16:51:50.210794Z","iopub.execute_input":"2026-02-18T16:51:50.211102Z","iopub.status.idle":"2026-02-18T16:51:50.830803Z","shell.execute_reply.started":"2026-02-18T16:51:50.211073Z","shell.execute_reply":"2026-02-18T16:51:50.830015Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7f0884018cd0>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"def estimate_loss(model):\n    out = {}\n    model.eval()\n    with torch.inference_mode():\n        for split in ['train', 'val']:\n            losses = torch.zeros(eval_iters)\n            for k in range(eval_iters):\n                X, Y = get_batch(split)\n                with ctx:\n                    logits, loss = model(X, Y)\n                losses[k] = loss.item()\n            out[split] = losses.mean()\n    model.train()\n    return out","metadata":{"id":"WtgFsCsU2lYN","trusted":true,"execution":{"iopub.status.busy":"2026-02-18T16:51:50.831783Z","iopub.execute_input":"2026-02-18T16:51:50.832021Z","iopub.status.idle":"2026-02-18T16:51:50.836993Z","shell.execute_reply.started":"2026-02-18T16:51:50.831998Z","shell.execute_reply":"2026-02-18T16:51:50.836324Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from torch.optim.lr_scheduler import LinearLR,SequentialLR, CosineAnnealingLR\n\n##PUT IN WEIGHT DECAY, CHANGED BETA2 to 0.95\noptimizer =  torch.optim.AdamW(model.parameters(), lr=learning_rate, betas=(0.9, 0.95), weight_decay=0.1, eps=1e-9) #weight decay for regularization\n\nscheduler_warmup = LinearLR(optimizer, total_iters = warmup_steps) #Implement linear warmup\nscheduler_decay = CosineAnnealingLR(optimizer,T_max = max_iters - warmup_steps, eta_min = min_lr) #Implement lr decay\nscheduler = SequentialLR(optimizer, schedulers=[scheduler_warmup, scheduler_decay], milestones=[warmup_steps]) #Switching from warmup to decay\n\n# https://stackoverflow.com/questions/72534859/is-gradscaler-necessary-with-mixed-precision-training-with-pytorch\nscaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))","metadata":{"id":"uXFFIfjg35W1","trusted":true,"execution":{"iopub.status.busy":"2026-02-18T16:51:50.839548Z","iopub.execute_input":"2026-02-18T16:51:50.839801Z","iopub.status.idle":"2026-02-18T16:51:55.439422Z","shell.execute_reply.started":"2026-02-18T16:51:50.839772Z","shell.execute_reply":"2026-02-18T16:51:55.438586Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_55/2132813893.py:11: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"\"\"\"best_val_loss = float('inf')\nbest_model_params_path = \"best_model_params.pt\"\ntrain_loss_list, validation_loss_list = [], []\n\n# Ensure model is on the correct device\nmodel = model.to(device)\n\n# In your training loop\nfor epoch in tqdm(range(max_iters)):\n    if epoch % eval_iters == 0 and epoch != 0:\n        # Ensure estimate_loss uses the correct device\n        losses = estimate_loss(model)\n        print(f\"Epoch {epoch}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n        print(f\"The current learning rate: {optimizer.param_groups[0]['lr']:.5f}\")\n        train_loss_list += [losses['train']]\n        validation_loss_list += [losses['val']]\n\n        if losses['val'] < best_val_loss:\n            best_val_loss = losses['val']\n            torch.save(model.state_dict(), best_model_params_path)\n\n    # Ensure X and y are on the correct device\n    X, y = get_batch(\"train\")\n    X, y = X.to(device), y.to(device)\n\n    with ctx:\n        logits, loss = model(X, y)\n        loss = loss / gradient_accumulation_steps\n        scaler.scale(loss).backward()\n\n    if ((epoch + 1) % gradient_accumulation_steps == 0) or (epoch + 1 == max_iters):\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n        scaler.step(optimizer)\n        scaler.update()\n        optimizer.zero_grad(set_to_none=True)\n    scheduler.step()\n    \"\"\"","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":208,"referenced_widgets":["bec3ce9a79144d148801a9336222be3c","c7ef6dca8f6e480691a5578341b3275b","732c6df37d4f46279d2d61fc783ef3ce","413a55220c6144a58d200c0e402dcc34","ec1cde1111b94e6c9b9d3575ab5c0ea1","5f77a6ab50b54591a485e2e1438f2786","9bd1814164c84f368fdc3a8947e7c6fe","3d1197eb129c4541a2de14fe9e258f37","fb98831d3fee41ccbac3db0ffa3e0ac4","de476eb1086943e0a3f31882a039d4f6","1e4a14a5ee0e495aa9c91e91f9081510"]},"id":"cIc6OzFO4C5T","outputId":"e4a8210f-ca4a-4bfb-a25d-d87b8e562d76","trusted":true,"execution":{"iopub.status.busy":"2026-02-18T16:51:55.440512Z","iopub.execute_input":"2026-02-18T16:51:55.440972Z","iopub.status.idle":"2026-02-18T16:51:55.446751Z","shell.execute_reply.started":"2026-02-18T16:51:55.440947Z","shell.execute_reply":"2026-02-18T16:51:55.446082Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'best_val_loss = float(\\'inf\\')\\nbest_model_params_path = \"best_model_params.pt\"\\ntrain_loss_list, validation_loss_list = [], []\\n\\n# Ensure model is on the correct device\\nmodel = model.to(device)\\n\\n# In your training loop\\nfor epoch in tqdm(range(max_iters)):\\n    if epoch % eval_iters == 0 and epoch != 0:\\n        # Ensure estimate_loss uses the correct device\\n        losses = estimate_loss(model)\\n        print(f\"Epoch {epoch}: train loss {losses[\\'train\\']:.4f}, val loss {losses[\\'val\\']:.4f}\")\\n        print(f\"The current learning rate: {optimizer.param_groups[0][\\'lr\\']:.5f}\")\\n        train_loss_list += [losses[\\'train\\']]\\n        validation_loss_list += [losses[\\'val\\']]\\n\\n        if losses[\\'val\\'] < best_val_loss:\\n            best_val_loss = losses[\\'val\\']\\n            torch.save(model.state_dict(), best_model_params_path)\\n\\n    # Ensure X and y are on the correct device\\n    X, y = get_batch(\"train\")\\n    X, y = X.to(device), y.to(device)\\n\\n    with ctx:\\n        logits, loss = model(X, y)\\n        loss = loss / gradient_accumulation_steps\\n        scaler.scale(loss).backward()\\n\\n    if ((epoch + 1) % gradient_accumulation_steps == 0) or (epoch + 1 == max_iters):\\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\\n        scaler.step(optimizer)\\n        scaler.update()\\n        optimizer.zero_grad(set_to_none=True)\\n    scheduler.step()\\n    '"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"best_val_loss = float('inf')\nbest_model_params_path = \"best_model_params.pt\"\ntrain_loss_list, validation_loss_list = [], []\n\nmodel = model.to(device)\n\neval_interval = 1000  # evaluate every 1000 steps (NOT 50)\n\nfor step in tqdm(range(max_iters)):\n\n    # ---- Evaluation ----\n    if step % eval_interval == 0 and step != 0:\n        model.eval()\n        losses = estimate_loss(model)\n        model.train()\n\n        print(f\"Step {step}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n        print(f\"Current learning rate: {optimizer.param_groups[0]['lr']:.6f}\")\n\n        train_loss_list.append(losses['train'])\n        validation_loss_list.append(losses['val'])\n\n        if losses['val'] < best_val_loss:\n            best_val_loss = losses['val']\n            torch.save(model.state_dict(), best_model_params_path)\n\n    # ---- Training ----\n    X, y = get_batch(\"train\")\n    X, y = X.to(device), y.to(device)\n\n    with torch.cuda.amp.autocast():\n        logits, loss = model(X, y)\n        loss = loss / gradient_accumulation_steps\n\n    scaler.scale(loss).backward()\n\n    # ---- Optimizer Step (with accumulation) ----\n    if (step + 1) % gradient_accumulation_steps == 0 or (step + 1 == max_iters):\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n        scaler.step(optimizer)\n        scaler.update()\n        optimizer.zero_grad(set_to_none=True)\n        scheduler.step()   # ✅ correct placement\n 9000/30000 [1:23:55<3:04:10,  1.90it/s]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T16:51:55.447636Z","iopub.execute_input":"2026-02-18T16:51:55.447919Z","iopub.status.idle":"2026-02-18T21:33:30.610116Z","shell.execute_reply.started":"2026-02-18T16:51:55.447885Z","shell.execute_reply":"2026-02-18T21:33:30.609198Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fc2845f2b5d4472938cce865db3c96b"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_55/304415725.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"name":"stdout","text":"Step 1000: train loss 3.4339, val loss 3.4364\nCurrent learning rate: 0.000200\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"Step 2000: train loss 2.9732, val loss 2.9960\nCurrent learning rate: 0.000300\nStep 3000: train loss 2.7663, val loss 2.7911\nCurrent learning rate: 0.000300\nStep 4000: train loss 2.6788, val loss 2.6810\nCurrent learning rate: 0.000299\nStep 5000: train loss 2.5860, val loss 2.5876\nCurrent learning rate: 0.000298\nStep 6000: train loss 2.5233, val loss 2.5388\nCurrent learning rate: 0.000297\nStep 7000: train loss 2.5104, val loss 2.5329\nCurrent learning rate: 0.000295\nStep 8000: train loss 2.5021, val loss 2.4781\nCurrent learning rate: 0.000293\nStep 9000: train loss 2.4915, val loss 2.5052\nCurrent learning rate: 0.000290\nStep 10000: train loss 2.4719, val loss 2.4341\nCurrent learning rate: 0.000288\nStep 11000: train loss 2.4711, val loss 2.4773\nCurrent learning rate: 0.000284\nStep 12000: train loss 2.4028, val loss 2.3841\nCurrent learning rate: 0.000281\nStep 13000: train loss 2.4034, val loss 2.4153\nCurrent learning rate: 0.000277\nStep 14000: train loss 2.4340, val loss 2.4249\nCurrent learning rate: 0.000272\nStep 15000: train loss 2.3539, val loss 2.3590\nCurrent learning rate: 0.000268\nStep 16000: train loss 2.3126, val loss 2.3560\nCurrent learning rate: 0.000263\nStep 17000: train loss 2.3945, val loss 2.3698\nCurrent learning rate: 0.000258\nStep 18000: train loss 2.3481, val loss 2.3477\nCurrent learning rate: 0.000252\nStep 19000: train loss 2.3310, val loss 2.3267\nCurrent learning rate: 0.000247\nStep 20000: train loss 2.3210, val loss 2.3268\nCurrent learning rate: 0.000241\nStep 21000: train loss 2.2862, val loss 2.2982\nCurrent learning rate: 0.000235\nStep 22000: train loss 2.3073, val loss 2.2637\nCurrent learning rate: 0.000228\nStep 23000: train loss 2.2830, val loss 2.2956\nCurrent learning rate: 0.000222\nStep 24000: train loss 2.2760, val loss 2.2622\nCurrent learning rate: 0.000215\nStep 25000: train loss 2.2869, val loss 2.2776\nCurrent learning rate: 0.000208\nStep 26000: train loss 2.2747, val loss 2.2561\nCurrent learning rate: 0.000201\nStep 27000: train loss 2.2306, val loss 2.2908\nCurrent learning rate: 0.000194\nStep 28000: train loss 2.2490, val loss 2.2880\nCurrent learning rate: 0.000187\nStep 29000: train loss 2.2565, val loss 2.3083\nCurrent learning rate: 0.000180\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ntrain_loss_list_converted = [i.cpu().detach() for i in train_loss_list]\nvalidation_loss_list_converted = [i.cpu().detach() for i in validation_loss_list]\n\nplt.plot(train_loss_list_converted, 'g', label='train_loss')\nplt.plot(validation_loss_list_converted, 'r', label='validation_loss')\nplt.xlabel(\"Steps - Every 100 epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()\n\n","metadata":{"id":"omts6URR4JhR","trusted":true,"execution":{"iopub.status.busy":"2026-02-18T21:33:30.611104Z","iopub.execute_input":"2026-02-18T21:33:30.611368Z","iopub.status.idle":"2026-02-18T21:33:30.873268Z","shell.execute_reply.started":"2026-02-18T21:33:30.611345Z","shell.execute_reply":"2026-02-18T21:33:30.872589Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"#Load the model\nmodel = Gemma3Model(GEMMA3_CONFIG_270M)  # re-create the model with same config\ndevice =  \"cuda\" if torch.cuda.is_available() else \"cpu\"\nbest_model_params_path = \"best_model_params.pt\"\nmodel.load_state_dict(torch.load(best_model_params_path, map_location=torch.device(device))) # load best model states\n","metadata":{"id":"2soOYi9B42pH","trusted":true,"execution":{"iopub.status.busy":"2026-02-18T21:33:30.874157Z","iopub.execute_input":"2026-02-18T21:33:30.874464Z","iopub.status.idle":"2026-02-18T21:33:31.30577Z","shell.execute_reply.started":"2026-02-18T21:33:30.874428Z","shell.execute_reply":"2026-02-18T21:33:31.304964Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"sentence = \"Once upon a time there was a\"\ncontext = (torch.tensor(enc.encode_ordinary(sentence)).unsqueeze(dim = 0))\ny = model.generate(context, 200)\nprint(enc.decode(y.squeeze().tolist()))","metadata":{"id":"PU1dDyCK43oC","trusted":true,"execution":{"iopub.status.busy":"2026-02-18T21:34:43.112771Z","iopub.execute_input":"2026-02-18T21:34:43.113461Z","iopub.status.idle":"2026-02-18T21:34:51.399823Z","shell.execute_reply.started":"2026-02-18T21:34:43.113432Z","shell.execute_reply":"2026-02-18T21:34:51.399151Z"}},"outputs":[{"name":"stdout","text":"Once upon a time there was a boy named Jake. Jake wanted to have a big nap, so he asked his mom for a fork. His mom said, â€œNo, Jake, fetch, and have to give the fork walking performing. now itâ€™s time for dinner, I will give you lots of berries for eating?\"\n\nJake looked sad, so he decided to accept his momâ€™s help. Together, they cooked a delicious berries and ate it up. When they full, Jake thanked the red fork and thanked his mom. They both kept eating the peanut butter and, spinning it around in the wind.\n\nJake was very tired. He loved his fork and wished him good choice. His mom always didn't understand what he was doing and had to be careless.\n\nJake smiled and said, \"Thanks Mom! See you soon!\"Once upon a time, there was a little girl who had a special heart. She could see that after all the other kids she\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"sentence = \"A little girl\"\ncontext = (torch.tensor(enc.encode_ordinary(sentence)).unsqueeze(dim = 0))\ny = model.generate(context, 200)\nprint(enc.decode(y.squeeze().tolist()))","metadata":{"id":"82b_kc15Dpim","trusted":true,"execution":{"iopub.status.busy":"2026-02-18T21:35:24.358353Z","iopub.execute_input":"2026-02-18T21:35:24.358868Z","iopub.status.idle":"2026-02-18T21:35:32.596121Z","shell.execute_reply.started":"2026-02-18T21:35:24.358841Z","shell.execute_reply":"2026-02-18T21:35:32.595327Z"}},"outputs":[{"name":"stdout","text":"A little girl was asking Ben hugs him. She said, \"That is my best gift. You look just in your coat. You should see that magic are my shoes! I forgive you quickly.\"\n\nBen tested the magic hat. He was amazed. He said, \"How did you do it?\" Sam said, \"I'm happy to see you. You played in your laughing way.\" He moved away from parties. He said, \"You lets I play with you too.\"\n\nShe put the magic glowing hat to make him feel soon. He continued to bow her touch. He hugged her and said, \"I love you. You are my little girl. You are my best friend.\" He smiled and faded away. He said, \"Now Lily, let's go to your room and have an ice cream will be out of now.\"S Tommy smiled and slowly walked towards his room. He entered the attic at the table, where his mom was there. He gazed at his bedroom and saw\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}